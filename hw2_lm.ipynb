{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ASSIGNMENT 2**: ZAKI KIDANE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CSCI 3832, Spring 2021, CU Boulder\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import nltk\n",
    "\n",
    "\n",
    "class LanguageModel:\n",
    "\n",
    "    def __init__(self, ngram_order, is_laplace_smoothing):\n",
    "        \n",
    "        #initialise the variables\n",
    "        self.ngram_order = ngram_order\n",
    "        self.is_laplace_smoothing = is_laplace_smoothing\n",
    "        self.token_freq = {} #this would store the unique words and their frequencies\n",
    "        self.ngram_dict = {} #this stores unique ngrams and their frequencies\n",
    "        self.ngram_minusone_dict = {} # for calculating the denominator count(the boy) for P(the |the boy) for instance\n",
    "        self.n_sentences = 0 # this will store the total number of sentences in a file\n",
    "        self.bad_vocab = {} #this is the list of vocabulary with frequency > 1\n",
    "        print(\"initialised\")\n",
    "\n",
    "      #the train function maps tokens to their frequencies and ngrams to their frequencies\n",
    "        #and outputs text files with the probabilities corresponding to each sentence\n",
    "    def train(self,filepath):\n",
    "        # first we empty the appropriate dictionaries so that training ngram counts from previous training files\n",
    "        #don't overlap with training from the current file\n",
    "        self.ngram_dict.clear()\n",
    "        self.ngram_minusone_dict.clear()\n",
    "        self.token_freq.clear()\n",
    "        self.bad_vocab.clear()\n",
    "        #we then declare tokens and ngrams as well as n-1 gram lists \n",
    "        tokens = []\n",
    "        ngrams = []\n",
    "        n_1grams = []\n",
    "        # indicating the name of the output file based on n-gram\n",
    "        with open(filepath) as lines:\n",
    "            for line in lines:\n",
    "                token = line.split()\n",
    "                tokens.extend(token)\n",
    "        freqs= Counter()\n",
    "        freqs.update(tokens)\n",
    "        self.token_freq = freqs\n",
    "        \n",
    "        \n",
    "        #replace frequency = 1 words with <unk> in token_freq dictionary and place words in bad_vocab\n",
    "        for key, value in self.token_freq:\n",
    "            if value == 1: \n",
    "                self.bad_vocab[key] = value\n",
    "                key = \"<unk>\"\n",
    "                \n",
    "                \n",
    "        #create ngram lists\n",
    "        ngrams = create_ngram(self.ngram_order, tokens)\n",
    "        \n",
    "        #create dictionaries with ngram tuples and their counts\n",
    "        freqs2= Counter()\n",
    "        freqs2.update(ngrams)\n",
    "        self.ngram_dict = freqs2\n",
    "        \n",
    "        #create n-1 gram lists and get their counts if ngram>=2\n",
    "        \n",
    "        if self.ngram_order > 1: \n",
    "            n_1grams = crate_ngram(self.ngram_order-1, tokens)\n",
    "            \n",
    "            #create dictionaries with ngram-1 tuples and their counts\n",
    "            freqs3= Counter()\n",
    "            freqs3.update(n_1grams)\n",
    "            self.ngram_dict = freqs3\n",
    "        \n",
    "        \n",
    "        \n",
    "        #test printed output\n",
    "        print('training done')\n",
    "        print('ngrams: ')\n",
    "        print(self.ngram_dict)\n",
    "        print('n-1 grams: ')\n",
    "        print(self.ngram_minusone_dict)\n",
    "        print('num of unique {}-grams :={}'.format(self.ngram_order, len(self.ngram_dict) ))#todo: put the proper variables\n",
    "        return ngrams\n",
    "    \n",
    "    #helper function for train to create ngrams\n",
    "    def create_ngram(n, tokens):\n",
    "        ngrams = []\n",
    "        for i in range(n-1,len(tokens)):\n",
    "            ngrams = tokens[i-n+1:i+1]\n",
    "            ngrams.append(tuple(ngram))\n",
    "        return ngram\n",
    "        \n",
    "        \n",
    "        #then use counter to create the dictionary with keys = (w1,w2) and values = frequency of (w1,w2)\n",
    "        \n",
    "    #for a given test sentence, this calculates P(sentence) = Ï€P(wi|w i-n+1)\n",
    "    def score(self, sentence):\n",
    "        #tokenize sentence\n",
    "        \n",
    "        # return the probability of the sentence\n",
    "        #for i in range(len(tokens)):\n",
    "        # if token not in goodword list replace with <unk>\n",
    "        #create ngram out of token\n",
    "        #for n_token in ngram, calculate count of ngram and n-1 gram\n",
    "        #multiply with markov chain or use log sum so P(sentence) = sum(log(P)) in for loop\n",
    "        \n",
    "        return\n",
    "\n",
    "    def getPerplexity(self, filename):\n",
    "        #return perplexity of the file\n",
    "\n",
    "        print('plexity using {}-grams :={}'.format())#todo: put the proper variables\n",
    "        return perplexity\n",
    "\n",
    "    def generate(self,num_sentences):\n",
    "        randomsentences=[]\n",
    "        \n",
    "\n",
    "        return randomsentences\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # ADDED\n",
    "    if len(sys.argv) != 3:\n",
    "        print(\"Usage:\", \"python hw2_lm.py berp-training.txt hw2-test.txt \")\n",
    "        sys.exit(1)\n",
    "\n",
    "    trainingFilePath = sys.argv[1]\n",
    "    testFilePath = sys.argv[2]\n",
    "    model = LanguageModel(2, False)\n",
    "    model.train(trainingFilePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
